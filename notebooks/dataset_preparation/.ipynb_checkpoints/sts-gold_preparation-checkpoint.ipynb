{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STS-Gold dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T15:46:04.464860Z",
     "start_time": "2019-04-27T15:46:04.462208Z"
    }
   },
   "source": [
    "Clean and prepare the sts-gold dataset. The set contains 2034 manually annotated tweets.\n",
    "\n",
    "The dataset can be downloaded from:\n",
    "https://github.com/pollockj/world_mood/tree/master/sts_gold_v03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python packages, initialize parameters and load dataset from csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T11:10:25.432941Z",
     "start_time": "2019-05-15T11:10:24.922714Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# activate tqdm for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize variables for the dataset headers and, input and output file locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T11:10:25.436423Z",
     "start_time": "2019-05-15T11:10:25.434365Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_csv = '../../data/external/sts-gold.csv'\n",
    "dataset_headers = ['id', 'polarity', 'tweet']\n",
    "\n",
    "clean_csv = '../../data/interim/sts-gold-clean.csv'\n",
    "\n",
    "test_txt = '../../reports/sts-gold_test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test dataset from disk and drop the unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T11:10:25.448175Z",
     "start_time": "2019-05-15T11:10:25.437563Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_csv, sep=';')\n",
    "df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remap polarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remap the positive sentiment polarity from 4 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T11:10:25.452387Z",
     "start_time": "2019-05-15T11:10:25.449396Z"
    }
   },
   "outputs": [],
   "source": [
    "df.polarity = df.polarity.map({0:0, 4:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cleanup steps will be applied on the dataset:\n",
    "\n",
    "1. Convert to lowercase\n",
    "2. decode all html encoded symbols\n",
    "3. tokenkize using nltk's twitter tokenizer\n",
    "4. Filter out all http link tokens\n",
    "5. Filter out all mentions tokens\n",
    "6. Filter out all hashtags tokens\n",
    "7. Filter out all tokens containing non-letter characters\n",
    "8. Join tokens back together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process text function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that will be applied to all texts in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T11:10:25.457703Z",
     "start_time": "2019-05-15T11:10:25.453843Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a set of all lowercase ascii character plus \"'\"\n",
    "letters = set(string.ascii_lowercase + \"'\")\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = list(filter(lambda t: not t.startswith('http'), tokens))\n",
    "    tokens = list(filter(lambda t: not t.startswith('@'), tokens))\n",
    "    tokens = list(filter(lambda t: not t.startswith('#'), tokens))\n",
    "    tokens = list(filter(lambda t: set(t).issubset(letters), tokens))\n",
    "    tokens = list(filter(lambda t: not t == \"'\", tokens))\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T11:10:25.877277Z",
     "start_time": "2019-05-15T11:10:25.458935Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2034/2034 [00:00<00:00, 4923.12it/s]\n"
     ]
    }
   ],
   "source": [
    "df.tweet = df.tweet.progress_map(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save clean datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned up dataset back to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T11:10:25.889332Z",
     "start_time": "2019-05-15T11:10:25.878584Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(clean_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate benchmark file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input file for SentiStrength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T11:10:25.900843Z",
     "start_time": "2019-05-15T11:10:25.890447Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bench = pd.read_csv(dataset_csv, sep=';')\n",
    "np.savetxt(test_txt, df_bench.tweet, fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "634px",
    "left": "1081px",
    "top": "54px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
